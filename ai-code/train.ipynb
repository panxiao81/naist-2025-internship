{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fc2124-b230-4de4-8292-a345aa4f605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, UnslothTrainer, UnslothTrainingArguments\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779b767e-d9ce-4df4-acd0-09a5af943e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.51.0.\n",
      "   \\\\   /|    NVIDIA A100-PCIE-40GB. Num GPUs = 1. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype=None\n",
    "load_in_4bit = True\n",
    "\n",
    "model_name = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bf8aad-f01e-4b28-9b58-252a06edbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('parquet', data_files='document-dataset.parquet')\n",
    "# dataset = datasets.load_from_disk('md-version-dataset')\n",
    "def formatting_prompts_func(examples):\n",
    "    return { \"text\": [example + tokenizer.eos_token for example in examples[\"text\"]] }\n",
    "\n",
    "dataset = dataset['train'].map(formatting_prompts_func, batched=True)\n",
    "#dataset = dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13d590c-2437-4bda-b79d-e21fd0785912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4387\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba9c870-6655-4d2e-aaae-9fa276f321a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "title: Policy Testing\n",
      "kind: documentation\n",
      "weight: 4\n",
      "restrictedtoc: true\n",
      "has_side_notes: true<|im_end|>\n",
      "------------------------\n",
      "OPA gives you a high-level declarative language\n",
      "(Rego) to author fine-grained policies that\n",
      "codify important requirements in your system.\n",
      "To help you verify the correctness of your policies, OPA also gives you a\n",
      "framework that you can use to write tests for your policies. By writing\n",
      "tests for your policies you can speed up the development process of new rules\n",
      "and reduce the amount of time it takes to modify rules as requirements evolve.\n",
      "{}\n",
      "The examples in this section try to represent the best practices. As such, they\n",
      "make use of keywords that are meant to become standard keywords at some point in\n",
      "time, but have been introduced gradually.\n",
      "See the docs on future keywords for more information.\n",
      "{}\n",
      "Getting Started\n",
      "Let's use an example to get started. The file below implements a simple\n",
      "policy that allows new users to be created and users to access their own\n",
      "profile.\n",
      "example.rego:\n",
      "```live:example:module:read_only,openable\n",
      "package authz\n",
      "allow if \n",
      "allow if \n",
      "```\n",
      "To test this policy, we will create a separate Rego file that contains test cases.\n",
      "example_test.rego:\n",
      "```live:example/test:module:read_only\n",
      "package authz_test\n",
      "import data.authz\n",
      "test_post_allowed if {\n",
      "    authz.allow with input as \n",
      "}\n",
      "test_get_anonymous_denied if {\n",
      "    not authz.allow with input as \n",
      "}\n",
      "test_get_user_allowed if {\n",
      "    authz.allow with input as \n",
      "}\n",
      "test_get_another_user_denied if {\n",
      "    not authz.allow with input as \n",
      "}\n",
      "```\n",
      "Both of these files are saved in the same directory.\n",
      "console\n",
      "$ ls\n",
      "example.rego      example_test.rego\n",
      "To exercise the policy, run the opa test command in the directory containing the files.\n",
      "```console\n",
      "$ opa test . -v\n",
      "data.authz_test.test_post_allowed: PASS (1.417Âµs)\n",
      "data.authz_test.test_get_anonymous_denied: PASS (426ns)\n",
      "data.authz_test.test_get_user_allowed: PASS (367ns)\n",
      "data.authz_test.test_get_another_user_denied: PASS (320ns)<|im_end|>\n",
      "------------------------\n",
      "PASS: 4/4\n",
      "```\n",
      "The opa test output indicates that all of the tests passed.\n",
      "Try exercising the tests a bit more by removing the first rule in example.rego.\n",
      "```console\n",
      "$ opa test . -v\n",
      "FAILURES<|im_end|>\n",
      "------------------------\n",
      "data.authz_test.test_post_allowed: FAIL (277.306Âµs)\n",
      "query:1                 Enter data.authz_test.test_post_allowed = _\n",
      "  example_test.rego:3     | Enter data.authz_test.test_post_allowed\n",
      "  example_test.rego:4     | | Fail data.authz_test.allow with input as \n",
      "  query:1                 | Fail data.authz_test.test_post_allowed = _\n",
      "SUMMARY\n",
      "data.authz_test.test_post_allowed: FAIL (277.306Âµs)\n",
      "data.authz_test.test_get_anonymous_denied: PASS (124.287Âµs)\n",
      "data.authz_test.test_get_user_allowed: PASS (242.2Âµs)\n",
      "data.authz_test.test_get_another_user_denied: PASS (131.964Âµs)<|im_end|>\n",
      "------------------------\n",
      "PASS: 3/4\n",
      "FAIL: 1/4\n",
      "```\n",
      "Enriched Test Report With Variable Values\n",
      "Sometimes, e.g. when testing rules with complex output, it can be useful to know more about the circumstances that caused a certain expression to fail a test.\n",
      "The --var-values flag can be used to enrich the test report with the exact expression that caused a test rule to fail, including the values of any variables or references used in the expression.\n",
      "Consider the following utility module:\n",
      "```live:example_vars:module:read_only,openable\n",
      "package authz\n",
      "allowed_actions(user) := [action |\n",
      "    user in data.actions[action]\n",
      "]\n",
      "```\n",
      "with accompanying tests:\n",
      "```live:example_vars/test:module:read_only\n",
      "package authz_test\n",
      "import data.authz\n",
      "test_allowed_actions_all_can_read if {\n",
      "    users := [\"alice\", \"bob\", \"jane\"]\n",
      "    r := [\"alice\", \"bob\"]\n",
      "    w := [\"jane\"]\n",
      "    p := \n",
      "every user in users<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "for row in dataset[:5]['text']:\n",
    "    print('------------------------')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96055ce4-f066-4457-8550-3d0ff070438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    use_rslora=False,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", # Add LoRA to all of the attention matrices\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\", # Add LoRA to all of the FFN matrices\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_dropout = 0, \n",
    "    bias = 'none',\n",
    "    use_gradient_checkpointing = 'unsloth',\n",
    "    random_state = 3407,\n",
    "    loftq_config = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36eebb08-f3a5-48cc-ad01-64e27cdb64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    dataset_num_proc = 4,\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 5e-5,\n",
    "        embedding_learning_rate = 5e-6,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        warmup_ratio = 0.1,\n",
    "        logging_steps = 10,\n",
    "        report_to = 'none',\n",
    "        seed=3407,\n",
    "        output_dir = 'result'\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7c58cc5a-0314-4d6d-9a09-e61a2b7ff5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4,387 | Num Epochs = 1 | Total steps = 274\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 485,212,160/5,000,000,000 (9.70% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='274' max='274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [274/274 11:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.083300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa1538c3-1c12-44c4-a1ba-8d928137a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system_prompt = \"\"\"\n",
    "#You are TerraformAI, an AI agent that builds and deploys Cloud Infrastructure written in Terraform HCL. Generate a description of the Terraform program you will define, followed by a single Terraform HCL program in response to each of my Instructions. Make sure the configuration is deployable. Create IAM roles as needed. If variables are used, make sure default values are supplied. Be sure to include a valid provider configuration within a valid region. Make sure there are no undeclared resources (e.g., as references) or variables, that is, all resources and variables needed in the configuration should be fully specified.\n",
    "#\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are TerraformAI, an AI agent that builds and deploys Cloud Infrastructure written in Terraform HCL.\n",
    "\"\"\"\n",
    "\n",
    "cot_prompt = \"\"\"\n",
    "Here are a few examples:\n",
    "\n",
    "Example prompt 1: Create an AWS RDS instance (with an instance class of db.t2.micro, and don't create a final snapshot before eventual deletion) with randomly generated id and password\n",
    "Example output 1: Let's think step by step. First, let's reason about the resources needed: this would be an AWS RDS instance (aws_db_instance), and resources to generate a random id and password. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_db_instance, we need to set the \"instance_class\" attribute to \"db.t2.micro\", and the \"skip_final_snapshot\" attribute to true. Finally, we connect the resources together, as needed: here \"identifier\" should be connected to the \"random_id\" resource, and \"password\" should be connected to the \"random_password\" resource\n",
    "```hcl\n",
    "resource \"random_id\" \"suffix\" {\n",
    "  byte_length = 4\n",
    "}\n",
    "\n",
    "resource \"random_password\" \"db\" {\n",
    "  length  = 16\n",
    "  special = false\n",
    "}\n",
    "\n",
    "resource \"aws_db_instance\" \"test\" {\n",
    "  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\n",
    "  allocated_storage   = 20 // Gigabytes\n",
    "  engine              = \"mysql\"\n",
    "  instance_class      = \"db.t2.micro\"\n",
    "  db_name                = \"metricbeattest\"\n",
    "  username            = \"foo\"\n",
    "  password            = random_password.db.result\n",
    "  skip_final_snapshot = true // Required for cleanup\n",
    "}\n",
    "```\n",
    "\n",
    "Example prompt 2: Create an 20GB MySQL instance on aws with randomly generated id and password\n",
    "Example output 2: Let's think step by step. First, let's reason about the resources needed: this would be an AWS RDS instance (aws_db_instance), and resources to generate a random id and password. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_db_instance, we need to set the \"engine\" attribute to \"mysql\". Finally, we connect the resources together, as needed: here \"identifier\" should be connected to the \"random_id\" resource, and \"password\" should be connected to the \"random_password\" resource\n",
    "```hcl\n",
    "resource \"random_id\" \"suffix\" {\n",
    "  byte_length = 4\n",
    "}\n",
    "\n",
    "resource \"random_password\" \"db\" {\n",
    "  length  = 16\n",
    "  special = false\n",
    "}\n",
    "\n",
    "resource \"aws_db_instance\" \"test\" {\n",
    "  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\n",
    "  allocated_storage   = 20 // Gigabytes\n",
    "  engine              = \"mysql\"\n",
    "  instance_class      = \"db.t2.micro\"\n",
    "  db_name                = \"metricbeattest\"\n",
    "  username            = \"foo\"\n",
    "  password            = random_password.db.result\n",
    "  skip_final_snapshot = true // Required for cleanup\n",
    "}\n",
    "```\n",
    "\n",
    "Example prompt 3: create a AWS EFS, and create a replica of an this created EFS file system using regional storage in us-west-2\n",
    "Example output 3: Let's think step by step. First, let's reason about the resources needed: this would be an AWS EFS replication resource (aws_efs_replication_configuration), and  the AWS EFS resource itself. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_efs_replication_configuration, we need to set the \"availability_zone_name\" attribute to an availability zone that will be within the region specificed in the prompt, such as \"us-west-2b\". Finally, we connect the resources together, as needed: here \"source_file_system_id\" should be connected to the \"aws_efs_file_system\" resource\n",
    "```hcl\n",
    "resource \"aws_efs_file_system\" \"example\" {}\n",
    "\n",
    "resource \"aws_efs_replication_configuration\" \"example\" {\n",
    "  source_file_system_id = aws_efs_file_system.example.id\n",
    "\n",
    "  destination {\n",
    "    availability_zone_name = \"us-west-2b\"\n",
    "    kms_key_id             = \"1234abcd-12ab-34cd-56ef-1234567890ab\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here is the actual prompt to answer. Let's think step by step:\n",
    "\"\"\"\n",
    "\n",
    "few_shot = \"\"\"\n",
    "Here are a few examples:\n",
    "\n",
    "Example prompt 1: Create an AWS RDS instance with randomly generated id and password\n",
    "Example output 1: \n",
    "```hcl\n",
    "resource \"random_id\" \"suffix\" {\n",
    "  byte_length = 4\n",
    "}\n",
    "\n",
    "resource \"random_password\" \"db\" {\n",
    "  length  = 16\n",
    "  special = false\n",
    "}\n",
    "\n",
    "resource \"aws_db_instance\" \"test\" {\n",
    "  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\n",
    "  allocated_storage   = 20 // Gigabytes\n",
    "  engine              = \"mysql\"\n",
    "  instance_class      = \"db.t2.micro\"\n",
    "  db_name                = \"metricbeattest\"\n",
    "  username            = \"foo\"\n",
    "  password            = random_password.db.result\n",
    "  skip_final_snapshot = true // Required for cleanup\n",
    "}\n",
    "```\n",
    "\n",
    "Here is the actual prompt to answer:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    #{\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": 'Create a DynamoDB Contributor Insights resource for a specific table with custom settings' }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fc4c2a69-c8c9-4e61-89b1-4df55475bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = 'pt',\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2478d689-4d2c-4990-b1c0-940fe6a54756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```hcl\n",
      "resource \"aws_dynamodb_contributor_insights\" \"example\" \n",
      "```\n",
      "The following is an example of how to configure the attributes of this resource:\n",
      "| Attribute | Type | Description |\n",
      "| --- | --- | --- |\n",
      "| arn | string | The ARN of the AWS account that will be used as the source for contributors insights. |\n",
      "| enabled | bool | Whether or not to enable contributor insights. |\n",
      "| name | string | The name of the contributor insights policy. |\n",
      "| partition_key_name | string | The name of the partition key in the table where the contributors insights should be applied. |\n",
      "| region | string | (Optional) The region where the resources reside. If omitted, it defaults to the current region. |\n",
      "| read_only | bool | Whether or not to apply the policy to all read-only endpoints. Defaults to false.<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,   4021,    264,  71813,\n",
       "           3506,  64724,  72037,   5101,    369,    264,   3151,   1965,    448,\n",
       "           2526,   5003, 151645,    198, 151644,  77091,    198,  73594,     71,\n",
       "            564,    198,   9233,    330,   8635,    814,  83348,  92581,   4831,\n",
       "          34386,   2796,      1,    330,   8687,      1,    715,  13874,   3989,\n",
       "            785,   2701,    374,    458,   3110,    315,   1246,    311,  14411,\n",
       "            279,   8201,    315,    419,   5101,    510,     91,  16752,    760,\n",
       "           3990,    760,   7662,   9248,     91,  12448,    760,  12448,    760,\n",
       "          12448,   9248,     91,    796,     77,    760,    914,    760,    576,\n",
       "           6261,     45,    315,    279,  23245,   2692,    429,    686,    387,\n",
       "           1483,    438,    279,   2530,    369,  20343,  25709,     13,   9248,\n",
       "             91,   8970,    760,   1807,    760,  13139,    476,    537,    311,\n",
       "           7283,  25305,  25709,     13,   9248,     91,    829,    760,    914,\n",
       "            760,    576,    829,    315,    279,  25305,  25709,   4842,     13,\n",
       "           9248,     91,  16658,   3097,   1269,    760,    914,    760,    576,\n",
       "            829,    315,    279,  16658,   1376,    304,    279,   1965,   1380,\n",
       "            279,  20343,  25709,   1265,    387,   9251,     13,   9248,     91,\n",
       "           5537,    760,    914,    760,    320,  15309,      8,    576,   5537,\n",
       "           1380,    279,   4963,  47283,     13,   1416,  39442,     11,    432,\n",
       "          16674,    311,    279,   1482,   5537,     13,   9248,     91,   1349,\n",
       "          18410,    760,   1807,    760,  13139,    476,    537,    311,   3796,\n",
       "            279,   4842,    311,    678,   1349,  15382,  36342,     13,  35990,\n",
       "            311,    895,     13, 151645]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "from threading import Thread\n",
    "# thread = Thread(model.generate, {'inputs': inputs,\n",
    "#     'streamer' : text_streamer,\n",
    "#     'max_new_tokens' : 256,\n",
    "#     'use_cache' : True,})\n",
    "# thread.start()\n",
    "\n",
    "# import textwrap\n",
    "# max_print_width = 1100\n",
    "\n",
    "# length = 0\n",
    "# for j, new_text in enumerate(text_streamer):\n",
    "#     if j == 0:\n",
    "#         wrapped_text = textwrap.wrap(new_text, width = max_print_width)\n",
    "#         length = len(wrapped_text[-1])\n",
    "#         wrapped_text = \"\\n\".join(wrapped_text)\n",
    "#         print(wrapped_text, end='')\n",
    "#     else:\n",
    "#         length += len(new_text)\n",
    "#         if length >= new_print_width:\n",
    "#             length = 0\n",
    "#             print()\n",
    "#         print(new_text, end = '')\n",
    "#     pass\n",
    "# pass\n",
    "\n",
    "model.generate(inputs=inputs, streamer=text_streamer,max_new_tokens=256,use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62ca61-6cf3-4f73-8a23-cc90a4617e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"Qwen2.5-1.5B-Instruct-IaC-merged\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d43b58-e7a1-4151-a44e-57705b108c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
